{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import (StructField,StructType,StringType,FloatType)\n",
    "\n",
    "from textblob import TextBlob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = sqlite3.connect(db_file)\n",
    "        return connection\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rows_from_sqlite(select_sql):\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(select_sql)\n",
    "        rows = c.fetchall()\n",
    "        c.close()  \n",
    "        \n",
    "        return rows\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_spark_df(select_sql, data_schema):\n",
    "    \n",
    "    rows = return_rows_from_sqlite(select_sql)\n",
    "    rdd = sc.parallelize(rows)\n",
    "    df = sqlContext.createDataFrame(rdd, StructType(fields=data_schema))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sentiment(text):\n",
    "\n",
    "    text = str(text)\n",
    "    \n",
    "    cleaned_text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", text).split()) \n",
    "\n",
    "    sentiment_analysis = TextBlob(cleaned_text) \n",
    "    \n",
    "    sentiment_score = sentiment_analysis.sentiment.polarity\n",
    "    \n",
    "    if sentiment_score < 0 :\n",
    "        return \"Negative\"\n",
    "    elif sentiment_score == 0:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_table(update_sql, parameters):\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(update_sql, parameters)\n",
    "        conn.commit()\n",
    "        c.close()  \n",
    "        \n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sentiment_table(updated_sentiment_df):\n",
    "    sql = ''' UPDATE sentiment_table\n",
    "              SET sentiment = ? \n",
    "              WHERE sentiment_id = ?'''\n",
    "   \n",
    "    sentiments_list = [x[\"sentiment\"] for x in updated_sentiment_df.rdd.collect()]\n",
    "    sentiment_ids_list = [x[\"sentiment_id\"] for x in updated_sentiment_df.rdd.collect()]\n",
    "    \n",
    "    for sentiment, sentiment_id in zip(sentiments_list,sentiment_ids_list):\n",
    "        parameters = (sentiment, sentiment_id)\n",
    "        update_table(sql, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "\n",
    "    global conn, sc, sqlContext\n",
    "\n",
    "    database = \"Twitter_Database.db\"   \n",
    "    conn = create_connection(database)\n",
    "\n",
    "    sc = SparkContext()\n",
    "    sqlContext = SQLContext(sc)\n",
    "\n",
    "    data_schema = [StructField('sentiment_id', StringType(), False),\n",
    "               StructField('user_name', StringType(), False),\n",
    "               StructField('tweet', StringType(), False),\n",
    "               StructField('longitude', FloatType(), False),\n",
    "               StructField('latitude', FloatType(), False),\n",
    "               StructField('sentiment', StringType(), True)\n",
    "              ]\n",
    "\n",
    "    select_sql = \"select * from sentiment_table where sentiment = ''\"\n",
    "\n",
    "    sentiment_df = return_spark_df(select_sql, data_schema)\n",
    "\n",
    "    sentiment_udf = udf(return_sentiment, StringType())\n",
    "\n",
    "    updated_sentiment_df = sentiment_df.withColumn('sentiment', sentiment_udf('tweet'))\n",
    "\n",
    "    update_sentiment_table(updated_sentiment_df)\n",
    "    \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
